[11/25/2024-18:42:09] [TRT] [I] [MemUsageChange] Init CUDA: CPU +2, GPU +0, now: CPU 392, GPU 6909 (MiB)
[11/25/2024-18:42:15] [TRT] [I] [MemUsageChange] Init builder kernel library: CPU +4688, GPU +1290, now: CPU 5236, GPU 8199 (MiB)
[11/25/2024-18:42:15] [TRT] [W] profileSharing0806 is on by default in TensorRT 10.0. This flag is deprecated and has no effect.
[11/25/2024-18:42:15] [TRT] [I] Local timing cache in use. Profiling results in this builder pass will not be stored.
[11/25/2024-18:42:15] [TRT] [I] Compiler backend is used during engine build.
[11/25/2024-18:42:17] [TRT] [I] Detected 3 inputs and 3 output network tensors.
[11/25/2024-18:42:17] [TRT] [I] Total Host Persistent Memory: 80 bytes
[11/25/2024-18:42:17] [TRT] [I] Total Device Persistent Memory: 0 bytes
[11/25/2024-18:42:17] [TRT] [I] Max Scratch Memory: 3321888768 bytes
[11/25/2024-18:42:17] [TRT] [I] [BlockAssignment] Started assigning block shifts. This will take 1 steps to complete.
[11/25/2024-18:42:17] [TRT] [I] [BlockAssignment] Algorithm ShiftNTopDown took 0.009502ms to assign 1 blocks to 1 nodes requiring 3321888768 bytes.
[11/25/2024-18:42:17] [TRT] [I] Total Activation Memory: 3321888768 bytes
[11/25/2024-18:42:17] [TRT] [I] Total Weights Memory: 33554816 bytes
[11/25/2024-18:42:17] [TRT] [I] Compiler backend is used during engine execution.
[11/25/2024-18:42:17] [TRT] [I] Engine generation completed in 2.12625 seconds.
[11/25/2024-18:42:17] [TRT] [I] [MemUsageStats] Peak memory usage of TRT CPU/GPU memory allocators: CPU 0 MiB, GPU 6144 MiB
[11/25/2024-18:42:19] [TRT] [I] Loaded engine size: 32 MiB
[11/25/2024-18:42:19] [TRT] [I] [MS] Running engine with multi stream info
[11/25/2024-18:42:19] [TRT] [I] [MS] Number of aux streams is 2
[11/25/2024-18:42:19] [TRT] [I] [MS] Number of total worker streams is 3
[11/25/2024-18:42:19] [TRT] [I] [MS] The main stream provided by execute/enqueue calls is the first worker stream
[11/25/2024-18:42:19] [TRT] [I] [MemUsageChange] TensorRT-managed allocation in IExecutionContext creation: CPU +0, GPU +3168, now: CPU 0, GPU 3200 (MiB)
model='roco' system='tensorrt' seqlen=4096
input_names=['q', 'k', 'v']
output_names=['out', 'roco_score', 'roco_sq_score']
check=True
tensorrt_llm not found
start_peak_mem_mib=128.0
[11/25/2024-18:42:19] [TRT] [W] Using default stream in enqueueV3() may lead to performance issues due to additional calls to cudaStreamSynchronize() by TensorRT to ensure correct synchronization. Please use non-default stream instead.
end_peak_mem_mib=161.0
gflops=137.438953472
mib=161.0
checking tensorrt...
out loss: {'abs_max': 0.001953125, 'abs_mean': 2.150864991889989e-05, 'rel_max': inf, 'rel_mean': inf, 'nz_rel_max': 2692.3333333333335, 'nz_rel_mean': 0.004967313532074916, 'mse': 1.5691470034117523e-09, 'rmse': 3.961246020397815e-05}
roco_score loss: {'abs_max': 0.0012178421020507812, 'abs_mean': 1.9683990501367932e-05, 'rel_max': 0.0014289209428210968, 'rel_mean': 2.4664113567878686e-05, 'nz_rel_max': 0.0014289209428210968, 'nz_rel_mean': 2.4664113567878686e-05, 'mse': 1.3907888182589852e-09, 'rmse': 3.7293281140964055e-05}
roco_sq_score loss: {'abs_max': 0.001204371452331543, 'abs_mean': 9.048250208249702e-07, 'rel_max': 0.006963516381454786, 'rel_mean': 0.00021249195581013184, 'nz_rel_max': 0.006963516381454786, 'nz_rel_mean': 0.00021249195581013184, 'mse': 7.99633551694045e-11, 'rmse': 8.942223167054404e-06}
warmup start
warmup done
[tensorrt] avg 9.2962 ms, min 9.2683 ms, max 9.3691 ms, 14784.418811047228 gflops/s (10 runs, 100 warmups, profiled)
