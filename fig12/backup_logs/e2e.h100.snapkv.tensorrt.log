[11/26/2024-03:55:53] [TRT] [I] [MemUsageChange] Init CUDA: CPU +2, GPU +0, now: CPU 353, GPU 6909 (MiB)
[11/26/2024-03:56:00] [TRT] [I] [MemUsageChange] Init builder kernel library: CPU +4688, GPU +1290, now: CPU 5197, GPU 8199 (MiB)
[11/26/2024-03:56:00] [TRT] [W] profileSharing0806 is on by default in TensorRT 10.0. This flag is deprecated and has no effect.
[11/26/2024-03:56:00] [TRT] [I] Local timing cache in use. Profiling results in this builder pass will not be stored.
[11/26/2024-03:56:00] [TRT] [I] Compiler backend is used during engine build.
[11/26/2024-03:56:03] [TRT] [I] Detected 3 inputs and 2 output network tensors.
[11/26/2024-03:56:03] [TRT] [I] Total Host Persistent Memory: 4352 bytes
[11/26/2024-03:56:03] [TRT] [I] Total Device Persistent Memory: 0 bytes
[11/26/2024-03:56:03] [TRT] [I] Max Scratch Memory: 3321888768 bytes
[11/26/2024-03:56:03] [TRT] [I] [BlockAssignment] Started assigning block shifts. This will take 3 steps to complete.
[11/26/2024-03:56:03] [TRT] [I] [BlockAssignment] Algorithm ShiftNTopDown took 0.027524ms to assign 2 blocks to 3 nodes requiring 3322413056 bytes.
[11/26/2024-03:56:03] [TRT] [I] Total Activation Memory: 3322413056 bytes
[11/26/2024-03:56:03] [TRT] [I] Total Weights Memory: 33554816 bytes
[11/26/2024-03:56:03] [TRT] [I] Compiler backend is used during engine execution.
[11/26/2024-03:56:03] [TRT] [I] Engine generation completed in 2.29702 seconds.
[11/26/2024-03:56:03] [TRT] [I] [MemUsageStats] Peak memory usage of TRT CPU/GPU memory allocators: CPU 0 MiB, GPU 4096 MiB
[11/26/2024-03:56:04] [TRT] [I] Loaded engine size: 32 MiB
[11/26/2024-03:56:04] [TRT] [I] [MS] Running engine with multi stream info
[11/26/2024-03:56:04] [TRT] [I] [MS] Number of aux streams is 2
[11/26/2024-03:56:04] [TRT] [I] [MS] Number of total worker streams is 3
[11/26/2024-03:56:04] [TRT] [I] [MS] The main stream provided by execute/enqueue calls is the first worker stream
[11/26/2024-03:56:04] [TRT] [I] [MemUsageChange] TensorRT-managed allocation in IExecutionContext creation: CPU +0, GPU +3168, now: CPU 0, GPU 3200 (MiB)
model='snapkv' system='tensorrt' seqlen=4096 layer_num=None
input_names=['q', 'k', 'v']
output_names=['out', 'snapkv_score']
tensorrt_llm not found
weight_zoo_path='/home/ppopp25_ae/ppopp25_ae/weight_zoo.json'
hf_config.num_hidden_layers=32
data_path='/home/ppopp25_ae/ppopp25_ae/vcsum.jsonl'
token_ids.shape=torch.Size([1, 4096])
token_ids.grad=None
using safe tensor: files={'model-00002-of-00002.safetensors', 'model-00001-of-00002.safetensors'}
  0%|          | 0/2 [00:00<?, ?it/s]100%|██████████| 2/2 [00:00<00:00, 134.15it/s]
  0%|          | 0/32 [00:00<?, ?it/s]  3%|▎         | 1/32 [00:00<00:04,  6.82it/s]  6%|▋         | 2/32 [00:00<00:04,  7.12it/s]  9%|▉         | 3/32 [00:00<00:03,  7.34it/s] 12%|█▎        | 4/32 [00:00<00:03,  7.44it/s] 16%|█▌        | 5/32 [00:00<00:03,  7.53it/s] 19%|█▉        | 6/32 [00:00<00:03,  7.47it/s] 22%|██▏       | 7/32 [00:00<00:03,  7.60it/s] 25%|██▌       | 8/32 [00:01<00:02,  8.13it/s] 31%|███▏      | 10/32 [00:01<00:02,  9.04it/s] 38%|███▊      | 12/32 [00:01<00:02,  9.45it/s] 41%|████      | 13/32 [00:01<00:01,  9.55it/s] 47%|████▋     | 15/32 [00:01<00:01,  9.81it/s] 53%|█████▎    | 17/32 [00:01<00:01, 10.02it/s] 59%|█████▉    | 19/32 [00:02<00:01, 10.16it/s] 66%|██████▌   | 21/32 [00:02<00:01,  9.86it/s] 69%|██████▉   | 22/32 [00:02<00:01,  9.34it/s] 72%|███████▏  | 23/32 [00:02<00:01,  8.84it/s] 75%|███████▌  | 24/32 [00:02<00:00,  8.55it/s] 78%|███████▊  | 25/32 [00:02<00:00,  8.69it/s] 81%|████████▏ | 26/32 [00:02<00:00,  8.96it/s] 84%|████████▍ | 27/32 [00:03<00:00,  8.93it/s] 88%|████████▊ | 28/32 [00:03<00:00,  8.41it/s] 91%|█████████ | 29/32 [00:03<00:00,  8.28it/s] 94%|█████████▍| 30/32 [00:03<00:00,  7.77it/s] 97%|█████████▋| 31/32 [00:03<00:00,  7.52it/s]100%|██████████| 32/32 [00:03<00:00,  7.87it/s]100%|██████████| 32/32 [00:03<00:00,  8.61it/s]
warmup start
[11/26/2024-03:57:08] [TRT] [W] Using default stream in enqueueV3() may lead to performance issues due to additional calls to cudaStreamSynchronize() by TensorRT to ensure correct synchronization. Please use non-default stream instead.
warmup done
[tensorrt] avg 466.0134 ms, min 462.3432 ms, max 469.8224 ms (50 runs, 50 warmups, profiled)
